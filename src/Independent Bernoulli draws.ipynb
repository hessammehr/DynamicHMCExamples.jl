{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We estimate a simple model of $n$ independent Bernoulli draws, with probability $\\alpha$. First, we load the packages we use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using ContinuousTransformations\n",
    "using DiffWrappers\n",
    "using DynamicHMC\n",
    "using MCMCDiagnostics\n",
    "using Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then define a structure to hold the data. For this model, the number of draws equal to $1$ is a sufficient statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliProblem"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Toy problem using a Bernoulli distribution.\n",
    "\n",
    "We model `n` independent draws from a ``Bernoulli(α)`` distribution.\n",
    "\"\"\"\n",
    "struct BernoulliProblem\n",
    "    \"Total number of draws in the data.\"\n",
    "    n::Int\n",
    "    \"Number of draws =1 in the data.\"\n",
    "    s::Int\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then make the type callable with the parameters *as a vector*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function (problem::BernoulliProblem)(θ)\n",
    "    α, = θ                                                # extract the parameter\n",
    "    @unpack n, s = problem                                # extract the data\n",
    "    s * log(α) + (n-s) * log(1-α) # log likelihood\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we need to \n",
    "\n",
    "1. transform from $\\mathbb{R}$ to the valid parameter domain $[0,1]$ for more efficient sampline, and\n",
    "\n",
    "2. calculate the derivatives for this transformed mapping.\n",
    "\n",
    "The helper packages take care of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = BernoulliProblem(100, 40)                             # original problem\n",
    "pt = TransformLogLikelihood(p, bridge(ℝ, Segment(0, 1)))  # transform\n",
    "pt∇ = ForwardGradientWrapper(pt, [0.0]);                  # AD using ForwardDiff.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we sample from the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample, NUTS_tuned = NUTS_init_tune_mcmc(Base.Random.GLOBAL_RNG, pt∇, 1, 1000);\n",
    "posterior = map(get_transformation(pt) ∘ get_position, sample);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sample` holds the sample (along with diagnostic information), while `NUTS_tuned` is the tuned sampler which would allow continuation of sampling. To get the posterior for $\\alpha$, we need to use `get_position` and transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4032038812140597"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior_α = first.(posterior)\n",
    "mean(posterior_α)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325.5188487615162"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ess_α = effective_sample_size(posterior_α)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hamiltonian Monte Carlo sample of length 1000\n",
       "  acceptance rate mean: 0.95, min/25%/median/75%/max: 0.49 0.93 0.98 1.0 1.0\n",
       "  termination: AdjacentTurn => 38% DoubledTurn => 62%\n",
       "  depth: 1 => 56% 2 => 37% 3 => 7%\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUTS_statistics(sample)         # NUTS-specific statistics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
